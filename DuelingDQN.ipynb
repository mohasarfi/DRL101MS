{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro \n",
    "In this notebook, we will implement a Dueling DQN algorithm which is an improvement over the simple DQN algorithm. Main paper for this algorithm is [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/abs/1511.06581).\n",
    "\n",
    "The genral idea is to separate the value and advantage functions. This separation allows the algorithm to learn the value of each state independently of the action, which can lead to better performance and faster convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRL101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e86b09bf04b4b28f13f8ff5e5d79a92a454be138b2dde21e7db36bb9d1dc0d8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
